{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efc712d2-8b62-4098-a986-76ec60c795c4",
   "metadata": {},
   "source": [
    "# AI Research Agent with MCP Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42777ce6-c826-4f1a-909f-f31aa9799e99",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/yauheniya-ai/Assets/blob/b98555dcb3938f531798dc5f318702a3e6fc03d2/Gifs/Robot.AI.gif?raw=true\" width=\"100\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f59fc7",
   "metadata": {},
   "source": [
    "## Define Resources and Prompts in the MCP Server "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dfa65e-1a60-4f64-abb5-597d0145652d",
   "metadata": {},
   "source": [
    "- The research server saves the information of the researched papers in a `json` file called `papers_info.json`, which is stored under a folder labeled with the topic name (the search term). \n",
    "\n",
    "- All the topics are stored under the `papers` directory. \n",
    "\n",
    "- **Resources** are read-only data that an MCP server can expose to the LLM application. Resources are defined in the MCP server using `FastMCP` with the use of the decorator `@mcp.resource(uri)`. Here, the MCP server provides two resources:\n",
    "    - list of available topic folders under the papers directory;\n",
    "    - the papers' information stored under a topic folder.\n",
    "- **Prompt template** can be provided with the server. It is defined using the decorator `@mcp.prompt()`. MCP will use `generate_search_prompt` as the prompt name, infer the prompt arguments from the function's argument and the prompt's description from the doc string.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc80f733-38aa-476a-8048-78033ebe98de",
   "metadata": {},
   "source": [
    "## Open the Inspector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d224d5af-3ba0-49be-b53b-e25b7666061b",
   "metadata": {},
   "source": [
    "- To open the terminal, run the `IFrame(\"http://127.0.0.1:8888/terminals/1\")` command. Replace the address `http://127.0.0.1:8888` if needed.\n",
    "- Activate the virtual environment:\n",
    "    - `source .venv/bin/activate`\n",
    "- Run the Inspector:\n",
    "    - `npx @modelcontextprotocol/inspector uv run --active research_server.py`\n",
    " \n",
    "<img src=\"./images/MCP_Inspector.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3486f985-1113-45ed-9d5a-fb7636e8a38e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"768\"\n",
       "            src=\"http://127.0.0.1:8888/terminals/1\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x103811810>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start the terminal\n",
    "import os\n",
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame(\"http://127.0.0.1:8888/terminals/1\", width=800, height=768)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f221f83-6e8b-431e-bd27-6dccedfac408",
   "metadata": {},
   "source": [
    "## Run the MCP Chatbot\n",
    "\n",
    "<img src=\"./images/MCP_Research_Agent.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83c1087-f208-42df-a167-6de840046a58",
   "metadata": {},
   "source": [
    "- To open another terminal, run the `IFrame(\"http://127.0.0.1:8888/terminals/2\")` command. Replace the address `http://127.0.0.1:8888` if needed.\n",
    "- Activate the virtual environment:\n",
    "    - `source .venv/bin/activate`\n",
    "- Run the chatbot:\n",
    "    - `uv run --active mcp_chatbot.py `\n",
    "- Query examples:\n",
    "    - `/prompt generate_search_prompt topic=\"ai_agents_in_defensive_cybersecurity\"`\n",
    "    - `create a visual diagram of the available ai agents in defensive cybersecurity based on the retrieved papers and save it to a text file`\n",
    "- To exit the chatbot, type `quit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a272a42a-4b7c-4215-9c36-af1e0e790354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"768\"\n",
       "            src=\"http://127.0.0.1:8888/terminals/2\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1038118a0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start the terminal\n",
    "import os\n",
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame(\"http://127.0.0.1:8888/terminals/2\", width=800, height=768)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04337af6-714b-4a52-9d4f-53483c4b4593",
   "metadata": {},
   "source": [
    "## References:\n",
    "\n",
    "DeepLearning.ai: [MCP: Build Rich-Context AI Apps with Anthropic](https://www.deeplearning.ai/short-courses/mcp-build-rich-context-ai-apps-with-anthropic/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05d7ed4-908c-489d-9a1e-de6d381ebf20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
